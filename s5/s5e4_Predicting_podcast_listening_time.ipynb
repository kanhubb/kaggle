{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a href=\"https://www.kaggle.com/code/diezejhon/the-voice-of-time-predicting-podcast-listening?scriptVersionId=236849981\" target=\"_blank\"><img align=\"left\" alt=\"Kaggle\" title=\"Open in Kaggle\" src=\"https://kaggle.com/static/images/open-in-kaggle.svg\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center>\n",
    "  <h1 style=\"background-color:#162B48; padding: 8px; color:white\"><strong>üéßüîçThe Voice of Time: Predicting Podcast Listening</strong></h1>\n",
    "\n",
    "  <img src=\"https://wintringham.org/wp-content/uploads/2020/01/listening-to-the-wintringham-podcast-scaled.jpg\" width=\"800\"/>\n",
    "\n",
    "<center> \n",
    "    \n",
    "<div class=\"list-group\" id=\"list-tab\" role=\"tablist\">\n",
    "\n",
    "  <h3 class=\"list-group-item list-group-item-action active\" style=\"background-color:#162B48; color:white\" data-toggle=\"list\"  role=\"tab\" aria-controls=\"home\"><strong>Summary</strong></h3> \n",
    "   <a class=\"list-group-item list-group-item-action\" data-toggle=\"list\" href=\"#guidingquestion\" role=\"tab\" aria-controls=\"profile\" style=\"color:#162B48\">Guiding Question<span class=\"badge badge-primary badge-pill\" style=\"background-color:#162B48; color:white\">1</span></a>\n",
    "  <a class=\"list-group-item list-group-item-action\" data-toggle=\"list\" href=\"#context\" role=\"tab\" aria-controls=\"profile\" style=\"color:#162B48\">Context<span class=\"badge badge-primary badge-pill\" style=\"background-color:#162B48; color:white\">2</span></a>\n",
    "  <a id=\"section2\" class=\"list-group-item list-group-item-action\" data-toggle=\"list\" href=\"#goal\" role=\"tab\" aria-controls=\"messages\" style=\"color:#162B48\">Goal<span class=\"badge badge-primary badge-pill\" style=\"background-color:#162B48; color:white\">3</span></a>\n",
    "  <a id=\"section2\" class=\"list-group-item list-group-item-action\" data-toggle=\"list\" href=\"#eda_univariate\" role=\"tab\" aria-controls=\"messages\" style=\"color:#162B48\">EDA Univariate<span class=\"badge badge-primary badge-pill\" style=\"background-color:#162B48; color:white\">4</span></a>\n",
    "  <a id=\"section2\" class=\"list-group-item list-group-item-action\" data-toggle=\"list\" href=\"#eda_multivariate\" role=\"tab\" aria-controls=\"messages\" style=\"color:#162B48\">EDA Multivariate<span class=\"badge badge-primary badge-pill\" style=\"background-color:#162B48; color:white\">5</span></a>\n",
    "  <a id=\"section2\" class=\"list-group-item list-group-item-action\" data-toggle=\"list\" href=\"#preprocessing\" role=\"tab\" aria-controls=\"messages\" style=\"color:#162B48\">Preprocessing<span class=\"badge badge-primary badge-pill\" style=\"background-color:#162B48; color:white\">6</span></a>\n",
    "  <a id=\"section2\" class=\"list-group-item list-group-item-action\" data-toggle=\"list\" href=\"#models\" role=\"tab\" aria-controls=\"messages\" style=\"color:#162B48\">Models<span class=\"badge badge-primary badge-pill\" style=\"background-color:#162B48; color:white\">7</span></a>\n",
    "  <a id=\"section2\" class=\"list-group-item list-group-item-action\" data-toggle=\"list\" href=\"#submission\" role=\"tab\" aria-controls=\"messages\" style=\"color:#162B48\">Submission<span class=\"badge badge-primary badge-pill\" style=\"background-color:#162B48; color:white\">8</span></a>\n",
    "  <a id=\"section2\" class=\"list-group-item list-group-item-action\" data-toggle=\"list\" href=\"#conclusion\" role=\"tab\" aria-controls=\"messages\" style=\"color:#162B48\">Conclusion<span class=\"badge badge-primary badge-pill\" style=\"background-color:#162B48; color:white\">9</span></a>\n",
    "  <a id=\"section2\" class=\"list-group-item list-group-item-action\" data-toggle=\"list\" href=\"#references\" role=\"tab\" aria-controls=\"messages\" style=\"color:#162B48\">References<span class=\"badge badge-primary badge-pill\" style=\"background-color:#162B48; color:white\">10</span></a>\n",
    "</div>    \n",
    "<br><br>\n",
    "<div style=\"font-family: Helvetica; line-height: 1.75; color: #000000; text-align: justify\">\n",
    "\n",
    "This notebook was developed in collaboration with <a style=\"color: #462F53\" href=\"https://www.kaggle.com/diezejhon\"> @diezejohn</a> and <a style=\"color: #462F53\" href=\"https://www.kaggle.com/feeldidaxie\"> @feeldidaxie</a>. If you found it useful, we‚Äôd appreciate your support on both notebooks!\n",
    "<br><br>\n",
    " <li> DiezeJohn notebook: <a style=\"color: #462F53\" href=\"https://www.kaggle.com/code/diezejhon/the-voice-of-time-predicting-podcast-listening\"> üéßüîçThe Voice of Time: Predicting Podcast Listening by diezejohn</a>\n",
    " <li> Feel Didaxie notebook: <a style=\"color: #462F53\" href=\"https://www.kaggle.com/code/feeldidaxie/the-voice-of-time-predicting-podcast-listening\"> üéßüîçThe Voice of Time: Predicting Podcast Listening by Feel Didaxie</a>\n",
    "</div>   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='guidingquestion'></a>\n",
    "# <div style=\" background-color:#162B48; color:white; padding: 12px; line-height: 1.5;\"><strong>1. | Guiding Question</strong></div>\n",
    "<div style=\"font-family: Helvetica; line-height: 1.75; color: #000000; text-align: justify\">\n",
    "\n",
    "Before diving into the heart of the matter, it is important <span style=\"background-color: #F6CECE; color: #000000;\">\n",
    "<strong>to define the problem we want to solve</strong></span>. No matter the project, we are always looking to solve a problem. This problem can vary‚Äîimproving security, improving resource management, reducing costs, and so on.\n",
    "<br><br>\n",
    "<strong><u>Example:</u></strong> \n",
    "Let‚Äôs imagine that we are working for an audio streaming platform (Spotify, YouTube Music, Deezer, etc.) and <span style=\"background-color: #F6CECE; color: #000000;\">we want to improve our podcast recommendations.</span>\n",
    "<br><br>\n",
    "One idea we can develop is: <span style=\"background-color: #F6CECE; color: #000000;\">for a given user, predict the listening time of a podcast X.</span> If we estimate that the user listens to more than half of the podcast, <u>it makes sense to recommend that podcast to them.</u>\n",
    "<br><br>\n",
    "For example, for user 1000, the model <strong>estimates</strong> that they will <strong>listen to 20 minutes</strong> of the first episode of the ‚ÄúTech News‚Äù podcast, <strong>which lasts 25 minutes</strong>. <span style=\"background-color: #F6CECE; color: #000000;\">\n",
    "<strong>This means the user will listen to 80% of the podcast.</strong></span> Therefore, the user is <u>interested</u> in this podcast, and <strong>it makes sense to recommend it</strong> to them.\n",
    "<br><br>\n",
    "To implement our idea, we can consider that if the user listens to <strong>50%</strong> of the podcast, we will recommend it to them. We can do this by creating a new variable called ‚ÄúRecommended,‚Äù with values ‚ÄúYes‚Äù and ‚ÄúNo.‚Äù This new variable can later be used in our recommendation algorithm.\n",
    "<br><br>\n",
    "Now that we‚Äôve developed the idea, it‚Äôs time to put it into practice <span style=\"background-color: #F6CECE; color: #000000;\">by collecting the data.</span> The data will be retrieved from the company‚Äôs database, usually in SQL, and then imported into Python.\n",
    "    \n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='context'></a>\n",
    "# <div style=\" background-color:#162B48; color:white; padding: 12px; line-height: 1.5;\"><strong>2. | Context</strong></div>\n",
    "\n",
    "## <div style=\" background-color: #D72729; color:white; padding: 10px; line-height: 1.5;\"><strong> Interpretation of variables üßæ </strong></div>\n",
    "\n",
    "<div style=\"font-family: Helvetica; line-height: 3; color: #000000; text-align: justify\">\n",
    "\n",
    "<center>\n",
    "<table style=\"width:80%\">\n",
    "  <thead>\n",
    "    <tr style = \"color : #262F3A\">\n",
    "      <th style=\"text-align: center; font-weight: bold; font-size: 15px; background-color: #F6CECE; line-height: 2;\">Name of variables</th>\n",
    "      <th style=\"text-align: center; font-weight: bold; font-size: 15px; background-color: #F6CECE; line-height: 2;\">Description</th>\n",
    "      <th style=\"text-align: center; font-weight: bold; font-size: 15px; background-color: #F6CECE; line-height: 2;\">Example</th>\n",
    "    </tr>\n",
    "  </thead>\n",
    "  <tbody>\n",
    "    <tr style= \"color: #262F3A\">\n",
    "       <td style= \"line-height: 2.5;\"><strong>Podcast_Name</strong></td>\n",
    "      <td>Name of the podcast</td>\n",
    "      <td>Tech Talk ; Health Hour ; Comedy Central</td>\n",
    "    </tr>\n",
    "    <tr style=\"background-color: #F6CECE; color: #262F3A\">\n",
    "      <td style= \"line-height: 2.5;\"><strong>Episode_Title</strong></td>\n",
    "      <td>Title of the podcast episode</td>\n",
    "      <td>The Future of AI ; Meditation Tips</td>\n",
    "    </tr>\n",
    "    <tr style=\"color: #262F3A\">\n",
    "      <td style= \"line-height: 2.5;\"><strong>Episode_Length</strong></td>\n",
    "      <td>Length of the episode <br> (in minutes)</td>\n",
    "      <td>5.0 ; 30.0 ; 60.0</td>\n",
    "    </tr>\n",
    "    <tr style=\"background-color: #F6CECE; color: #262F3A\">\n",
    "      <td style= \"line-height: 2.5;\"><strong>Genre</strong></td>\n",
    "      <td>Genre of the podcast episode</td>\n",
    "      <td>Technology ; Comedy ; Health</td>\n",
    "    </tr>\n",
    "    <tr style= \"color: #262F3A\">\n",
    "      <td style= \"line-height: 2.5;\"><strong>Host_Popularity</strong></td>\n",
    "      <td>Popularity of the host <br> (scale: 0 to 100)</td>\n",
    "      <td>50.0 ; 75.0 ; 90.0</td>\n",
    "    </tr>\n",
    "    <tr style=\"background-color: #F6CECE; color: #262F3A\">\n",
    "      <td style= \"line-height: 2.5;\"><strong>Publication_Day</strong></td>\n",
    "      <td>Day of the week the episode was published</td>\n",
    "      <td>Monday ; Wednesday ; Saturday</td>\n",
    "    </tr>\n",
    "    <tr style= \"color: #262F3A\">\n",
    "      <td style= \"line-height: 2.5;\"><strong>Publication_Time</strong></td>\n",
    "      <td>Time of the day the episode was published</td>\n",
    "      <td>Morning ; Evening ; Night</td>\n",
    "    </tr>\n",
    "    <tr style=\"background-color: #F6CECE; color: #262F3A\">\n",
    "      <td style= \"line-height: 2.5;\"><strong>Guest_Popularity</strong></td>\n",
    "      <td>Popularity of the guest (if any) <br> (scale: 0 to 100)</td>\n",
    "      <td>20.0 ; 50.0 ; 85.0</td>\n",
    "    </tr>\n",
    "    <tr style= \"color: #262F3A\">\n",
    "      <td style= \"line-height: 2.5;\"><strong>Number_of_Ads</strong></td>\n",
    "      <td>Number of ads in the episode</td>\n",
    "      <td>0 ; 1 ; 2 ; 3</td>\n",
    "    </tr>\n",
    "    <tr style=\"background-color: #F6CECE; color: #262F3A\">\n",
    "      <td style= \"line-height: 2.5;\"><strong>Episode_Sentiment</strong></td>\n",
    "      <td>Overall sentiment of the episode content</td>\n",
    "      <td>Positive ; Neutral ; Negative</td>\n",
    "    </tr>\n",
    "    <tr style= \"color: #262F3A\">\n",
    "      <td style= \"line-height: 2.5;\"><strong>Listening_Time</strong></td>\n",
    "      <td>Average actual listening time <br> (target variable, in minutes)</td>\n",
    "      <td>4.5 ; 8.0 ; 30.0 ; 60.0</td>\n",
    "    </tr>\n",
    "  </tbody>\n",
    "</table>\n",
    "</center>\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='goal'></a>\n",
    "# <div style=\" background-color:#162B48; color:white; padding: 12px; line-height: 1.5;\"><strong>3. | Goal</strong></div>\n",
    "\n",
    "<div style=\"font-family: Helvetica; line-height: 1.75; color: #000000; text-align: justify\">\n",
    "\n",
    "Our goal is <span style=\"background-color: #F6CECE; color: #000000;\">\n",
    "<strong>to predict, for a given user, the listening duration of a podcast X as accurately as possible.</strong></span>\n",
    "<br><br>\n",
    "For example, if <u>user 200 listens to the podcast ‚ÄúTech News‚Äù for 25 minutes</u>, our model should ideally <u>predict a duration close to 25 minutes</u>.\n",
    "<br><br>\n",
    "To evaluate the performance of our regression model, we use <strong>the Root Mean Squared Error (RMSE).</strong>\n",
    "<br><br>\n",
    "<u>RMSE</u> corresponds to the square root of the average of the squared prediction errors. It quantifies, in minutes, the average difference between the predicted values and the actual values.\n",
    "<br><br>\n",
    "For instance, <span style=\"background-color: #F6CECE; color: #000000;\">an RMSE of 10 means that, on average, the model is off by ¬±10 minutes.</span> In other words, for a prediction of <strong>60 minutes</strong>, the actual duration could reasonably <strong>fall between 50 and 70 minutes</strong>.\n",
    "<br><br>\n",
    "The lower the RMSE, the more accurate the model, thus improving the quality of our recommendations.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='eda_univariate'></a>\n",
    "# <div style=\" background-color:#162B48; color:white; padding: 12px; line-height: 1.5;\"><strong>4. | EDA Univariate </strong></div>\n",
    "\n",
    "<div style=\"font-family: Helvetica; line-height: 1.75; color: #000000; text-align: justify\">\n",
    "\n",
    "In this section, <u>we will analyze the data to better understand it.</u><br>\n",
    "The goal is to assess how <strong>the data is distributed</strong>, identify any <strong>outliers</strong> or <strong>missing values</strong>, and determine whether we need <strong>to simplify certain variables</strong> through feature engineering.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <div style=\" background-color: #D72729; color:white; padding: 10px; line-height: 1.5;\"><strong>4.1 | Import libraries üìö  </strong></div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Installing Libraries ---\n",
    "!pip install ydata-profiling\n",
    "!pip install Pillow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----- Handling data -----\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "# ----- Graphics -----\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from matplotlib.patches import Rectangle\n",
    "import matplotlib.colors as mcolors\n",
    "from matplotlib.lines import Line2D\n",
    "\n",
    "# ----- EDA Univariate -----\n",
    "from ydata_profiling import ProfileReport\n",
    "\n",
    "\n",
    "# ----- Remove the warnings -----\n",
    "import warnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove the warnings\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <div style=\" background-color: #D72729; color:white; padding: 10px; line-height: 1.5;\"><strong>4.2 | Import the data</strong></div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "import os\n",
    "import gdown\n",
    "import pandas as pd\n",
    "\n",
    "# Create the directory for storing files\n",
    "DATA_DIR = \"data\"\n",
    "os.makedirs(DATA_DIR, exist_ok=True)\n",
    "\n",
    "# Google Drive file IDs (replace with actual IDs)\n",
    "TRAIN_FILE_ID = \"11jqh_p8GmcCysZqlltyLvyOEfPIe-JxO\"\n",
    "TEST_FILE_ID = \"1ipar15ihqez37OQD14_uNZ4U8CrUIfhJ\"\n",
    "\n",
    "\n",
    "# File paths\n",
    "train_output = os.path.join(DATA_DIR, \"train.csv\")\n",
    "test_output = os.path.join(DATA_DIR, \"test.csv\")\n",
    "\n",
    "# Download train.csv\n",
    "print(\"üì• Downloading train.csv...\")\n",
    "gdown.download(f\"https://drive.google.com/uc?id={TRAIN_FILE_ID}\", train_output, quiet=False)\n",
    "\n",
    "# Download test.csv\n",
    "print(\"üì• Downloading test.csv...\")\n",
    "gdown.download(f\"https://drive.google.com/uc?id={TEST_FILE_ID}\", test_output, quiet=False)\n",
    "\n",
    "# Load into Pandas DataFrame\n",
    "print(\"üìä Loading data into DataFrames...\")\n",
    "df_train = pd.read_csv(train_output,index_col=\"id\")\n",
    "df_test = pd.read_csv(test_output,index_col=\"id\")\n",
    "\n",
    "# Confirm shapes\n",
    "print(\"\\n‚úÖ Files downloaded successfully!\")\n",
    "print(f\"Train shape: {df_train.shape}\")\n",
    "print(f\"Test shape: {df_test.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.head(3).style.background_gradient(cmap='Blues').hide(axis=\"index\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test.head(3).style.background_gradient(cmap='Blues').hide(axis=\"index\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <div style=\" background-color: #D72729; color:white; padding: 10px; line-height: 1.5;\"><strong>4.3 | Dataset Exploration</strong></div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Convert Episode Title into category ---\n",
    "df_train[\"Episode_Title\"] = df_train[\"Episode_Title\"].astype(\"category\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----- Dataset Report with ProfileReport for the train set -----\n",
    "\n",
    "ProfileReport(df_train, title='Train Dataset', \n",
    "              minimal = False, \n",
    "              progress_bar = False, \n",
    "              samples = None, \n",
    "              interactions = None,\n",
    "              correlations = None,\n",
    "              explorative = True,\n",
    "              notebook = {'iframe':{'height': '600px'}},\n",
    "              missing_diagrams = {'heatmap': False, 'dendrogram': True}).to_notebook_iframe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"font-family: Helvetica; line-height: 1.8; color: #000000; text-align: justify\">\n",
    "\n",
    "\n",
    "<span style=\"background-color: #F6CECE; color: #000000; font-size: 18px;\"><strong><u> Overview:</u></strong></span>\n",
    "<br><br>    \n",
    "We have <strong>11 variables</strong>, with <strong>750,000 podcast listen</strong>s and <strong>2.8% missing data</strong>.\n",
    "<blockquote style=\"color: #000000;\">\n",
    "<li><u><strong>Podcast Name:</strong></u> There are <strong>48</strong> different podcast names. If we encode this variable, we would add 48 new features to our model, which could cause dimensionality issues. It would be wise <span style=\"background-color: #F6CECE; color: #000000;\">to either remove or simplify it</span> ‚Äî for example, by grouping into 6 categories instead of 48.</li>\n",
    "\n",
    "<li><u><strong>Episode Title:</strong></u> There are <b>100</b> different episodes, ranging from Episode 1 to Episode 100. As with ‚ÄúPodcast_Name,‚Äù we will either need <span style=\"background-color: #F6CECE; color: #000000;\">to simplify or remove</span> this variable.</li>\n",
    "\n",
    "<li><u><strong>Episode Length minutes:</strong></u> On <strong>average</strong>, an episode lasts <strong>64 minutes</strong>. However, <strong>the distribution is uniform</strong>, meaning all durations are properly represented (there is no underrepresentation). Episode lengths range from <strong>0 to 325.24 minutes</strong>. <span style=\"background-color: #F6CECE; color: #000000;\">Episodes longer than 119.99 minutes are considered outliers</span>, as they account for only 9 listens. Additionally, <strong>11.6% of the values are missing</strong>.</li>\n",
    "\n",
    "<li><u><strong>Genre:</strong></u> There are <strong>10</strong> different genres. The most listened-to genre is ‚ÄúSports,‚Äù followed by ‚ÄúTechnology.‚Äù</li>\n",
    "\n",
    "<li><u><strong>Host Popularity Percentage:</strong></u> On <strong>average</strong>, the podcast host has a popularity rating of <strong>60%</strong>. However, <strong>the distribution is uniform</strong>, meaning there are both very popular and unknown hosts. Values range from <strong>0% to 119%</strong>, indicating the presence of <strong>outliers</strong>.</li>\n",
    "\n",
    "<li><u><strong>Publication Day:</strong></u> There are <strong>7</strong> different days, <strong>distributed uniformly</strong>. Podcasts are just as likely to be published on a Monday as on a Sunday.</li>\n",
    "\n",
    "<li><u><strong>Publication Time:</strong></u> There are <strong>4</strong> different publication times, <strong>distributed uniformly</strong>. Podcasts are just as likely to be published in the morning as in the evening.</li>\n",
    "\n",
    "<li><u><strong>Guest Popularity Percentage:</strong></u> On <strong>average</strong>, a podcast guest has a popularity rating of <strong>52%</strong>. However, <strong>the distribution is uniform</strong>, with both well-known and unknown guests. <strong>19.5%</strong> of the values are missing, possibly indicating episodes without guests. Values range from <strong>0% to 119%</strong>, meaning there are <strong>outliers</strong>.</li>\n",
    "\n",
    "<li><u><strong>Number of Ads:</strong></u> The number of ads during a listen ranges from <strong>0 to 103 ads</strong>. However, only <strong>7</strong> listens had <strong>more than 3 ads</strong>, which are considered <strong>outliers</strong>. <strong>60%</strong> of listens had 0 or 1 ad. There is 1 missing value.</li>\n",
    "\n",
    "<li><u><strong>Episode Sentiment:</strong></u> There are <strong>3</strong> categories, <strong>distributed uniformly</strong>. This means there are as many positive, negative, and neutral episodes.</li>\n",
    "\n",
    "<li><u><strong>Listening Time minutes:</strong></u> On <strong>average</strong>, users listen to a podcast for <strong>45 </strong>minutes. <span style=\"background-color: #F6CECE; color: #000000;\">50% of users listen to a podcast for between 23 and 64 minutes</span>.</li>\n",
    "     </blockquote>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----- Dataset Report with ProfileReport for the test set -----\n",
    "\"\"\"\n",
    "ProfileReport(df_test, title='Test Dataset', \n",
    "              minimal = False, \n",
    "              progress_bar = False, \n",
    "              samples = None, \n",
    "              interactions = None,\n",
    "              correlations = None,\n",
    "              explorative = True,\n",
    "              notebook = {'iframe':{'height': '600px'}},\n",
    "              missing_diagrams = {'heatmap': False, 'dendrogram': True}).to_notebook_iframe()\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <div style=\" background-color: #D72729; color:white; padding: 10px; line-height: 1.5;\"><strong>4.4 | Outlier</strong></div>\n",
    "\n",
    "<div style=\"font-family: Helvetica; line-height: 1.8; color: #000000; text-align: justify\">\n",
    "\n",
    "<u>We will handle outliers for the following variables:</u>\n",
    "\n",
    "<li><u><strong>Episode Length minutes:</strong></u> Outliers will be replaced with <strong>119.99</strong>.</li>\n",
    "\n",
    "<li><u><strong>Host Popularity Percentage:</strong></u> Outliers will be replaced with <strong>100</strong>.</li>\n",
    "\n",
    "<li><u><strong>Guest Popularity Percentage:</strong></u> Outliers will be replaced with <strong>100</strong>.</li>\n",
    "\n",
    "<li><u><strong>Number of Ads:</strong></u> Outliers will be replaced with <strong>3</strong>.</li>\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### -------------------------------- Handling outlier --------------------------------\n",
    "\n",
    "\n",
    "# Limit episode length to a max of 119.99\n",
    "df_train['Episode_Length_minutes'] = df_train['Episode_Length_minutes'].clip(upper=119.99)\n",
    "print(\"Max Episode Length Minutes:\", df_train[\"Episode_Length_minutes\"].max())\n",
    "\n",
    "# Limit  host popularity percentange to a max of 100%\n",
    "df_train['Host_Popularity_percentage'] = df_train['Host_Popularity_percentage'].clip(upper=100)\n",
    "print(\"Max Host Popularity Percentage:\", df_train[\"Host_Popularity_percentage\"].max())\n",
    "\n",
    "# Limit  guest popularity percentange to a max of 100%\n",
    "df_train['Guest_Popularity_percentage'] = df_train['Guest_Popularity_percentage'].clip(upper=100)\n",
    "print(\"Max Guest Popularity Percentage:\", df_train[\"Guest_Popularity_percentage\"].max())\n",
    "\n",
    "# Limit number of ads to a max of 3 ads\n",
    "df_train['Number_of_Ads'] = df_train['Number_of_Ads'].clip(upper=3)\n",
    "print(\"Max Number of Ads:\", df_train[\"Number_of_Ads\"].max())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <div style=\" background-color: #D72729; color:white; padding: 10px; line-height: 1.5;\"><strong>4.5 | Feature Engineering</strong></div>\n",
    "\n",
    "<div style=\"font-family: Helvetica; line-height: 1.8; color: #000000; text-align: justify\">\n",
    "\n",
    "<u>We will simplify or remove the following variables:</u>\n",
    "\n",
    "<li><u><strong>Podcast Name:</strong></u> We will <strong>remove</strong> this variable. (48 categories)</li>\n",
    "\n",
    "<li><u><strong>Episode Title:</strong></u> We will <strong>simplify this variable</strong> into 4 categories to indicate whether the podcast is from the beginning (episodes 1 to 25), early middle (episodes 26 to 50), late middle (episodes 51 to 75), or end (episodes 76 to 100). (100 categories)</li>\n",
    "</div>    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### -------------------------------- Simplifying a variable --------------------------------\n",
    "\n",
    "\n",
    "# Import Library\n",
    "import re\n",
    "\n",
    "# Extract episode number from title\n",
    "df_train['Episode_Number'] = df_train['Episode_Title'].apply(lambda x: int(re.search(r'\\d+', x).group()))\n",
    "\n",
    "# Create categories by episode number\n",
    "df_train['Episode_Category'] = pd.cut(df_train['Episode_Number'], \n",
    "                                    bins=[0, 25, 50, 75, 100], \n",
    "                                    labels=['Start', 'Early Middle', 'Late Middle', 'End'], \n",
    "                                    right=True)\n",
    "\n",
    "df_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <div style=\" background-color: #D72729; color:white; padding: 10px; line-height: 1.5;\"><strong>4.6 | Missing values</strong></div>\n",
    "\n",
    "<div style=\"font-family: Helvetica; line-height: 1.8; color: #000000; text-align: justify\">\n",
    "\n",
    "<u>We will handle missing values for the following variables:</u>\n",
    "\n",
    "<li><u><strong>Episode Length minutes:</strong></u> <strong>11.6%</strong> missing values.</li>\n",
    "\n",
    "<li><u><strong>Guest Popularity Percentage:</strong></u> <strong>19%</strong> missing values.</li>\n",
    "\n",
    "<li><u><strong>Number of Ads:</strong></u> We will <strong>delete</strong> the single missing value.</li>\n",
    "<br><br>\n",
    "<u><strong>Episode Length minutes:</strong></u>\n",
    "\n",
    "To fill in the missing episode duration values, we could use <span style=\"background-color: #F6CECE; color: #000000;\"><strong>a reference value</strong></span> associated with each episode.\n",
    "\n",
    "For example, if the podcast <strong>\"Mystery Matters\"</strong> episode <strong>98</strong> lasts <strong>35</strong> minutes, for the same episode, <span style=\"background-color: #F6CECE; color: #000000;\">we could simply replace missing values with ‚Äú35‚Äù.</span>\n",
    "    \n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show null values for Episode Length Minutes\n",
    "df_train[\n",
    "    (df_train['Podcast_Name'] == \"Mystery Matters\") & (df_train['Episode_Length_minutes'].isna())\n",
    "].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show not null values for Episode Length Minutes\n",
    "df_train[\n",
    "    (df_train['Podcast_Name'] == \"Mystery Matters\") & (df_train['Episode_Length_minutes'].notna())\n",
    "].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"font-family: Helvetica; line-height: 1.8; color: #000000; text-align: justify\">\n",
    "\n",
    "Unfortunately, <u>we observe that for the same episode of the same podcast</u>, the recorded durations vary significantly. <strong>There must be an error in the data.</strong>\n",
    "Since we cannot contact the Data Engineer, we must find another solution.\n",
    "<br><br>\n",
    "<u>To handle the missing episode duration values, we will test two methods:</u>\n",
    "\n",
    "<li>KNN (K-Nearest Neighbors) imputation</li>\n",
    "\n",
    "<li>Median imputation based on episode duration</li>\n",
    "<br>\n",
    "<u>To determine which method is more effective, we will conduct a test:</u>\n",
    "<br>\n",
    "We will take <strong>a sample of 10,000 entries</strong>, artificially <strong>remove 2,000 known</strong> episode duration values, and <strong>then apply KNN and median imputation</strong>. After processing, <span style=\"background-color: #F6CECE; color: #000000;\"><strong>we will compare the predicted values to the actual ones and choose the method that results in the lowest error</strong></span>.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----- Handling missing values -----\n",
    "from sklearn.impute import KNNImputer\n",
    "\n",
    "# ----- Evaluating the quality of imputation -----\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### -------------------------------- 1. Test for missing values --------------------------------\n",
    "\n",
    "\n",
    "### ---------------- 2. Setting up the test ----------------\n",
    "\n",
    "# Take non-missing values\n",
    "df_complete = df_train[df_train['Episode_Length_minutes'].notna()].copy()\n",
    "\n",
    "# Take a sample of 10,000 users\n",
    "df_sample = df_complete.sample(n=10_000, random_state=42).copy()\n",
    "\n",
    "# Take only independent variables\n",
    "df_sample = df_sample[[\"Episode_Length_minutes\", \"Genre\", \"Host_Popularity_percentage\",\n",
    "            \"Publication_Day\", \"Publication_Time\", \"Guest_Popularity_percentage\",\n",
    "            \"Number_of_Ads\", \"Episode_Sentiment\", \"Episode_Category\"]]\n",
    "\n",
    "# Encode qualitative variables into quantitative ones\n",
    "df_sample_encoded = pd.get_dummies(data = df_sample , drop_first = True)\n",
    "\n",
    "# Make a copy\n",
    "df_nan = df_sample_encoded.copy()\n",
    "\n",
    "# Take the index of 20% of the dataset\n",
    "missing_indices = df_nan.sample(frac=0.2, random_state=42).index\n",
    "\n",
    "# Take indexes and set them to missing values\n",
    "df_nan.loc[missing_indices, 'Episode_Length_minutes'] = np.nan\n",
    "### -------------------------------------------------------\n",
    "\n",
    "\n",
    "\n",
    "### ---------------- 3. KNN Imputation ----------------\n",
    "\n",
    "# Take the 10 nearest neighbors\n",
    "imputer = KNNImputer(n_neighbors=10)\n",
    "\n",
    "# Apply KNN\n",
    "df_imputed = pd.DataFrame(imputer.fit_transform(df_nan), \n",
    "                          columns = df_nan.columns, \n",
    "                          index = df_nan.index)\n",
    "\n",
    "# Take the values predicted by KNN and the true values\n",
    "imputed_values = df_imputed.loc[missing_indices, 'Episode_Length_minutes']\n",
    "original_values = df_sample_encoded.loc[missing_indices, 'Episode_Length_minutes']\n",
    "### -------------------------------------------------------\n",
    "\n",
    "\n",
    "\n",
    "### ---------------- 4. Median Imputation ----------------\n",
    "\n",
    "# Take the median\n",
    "median_value = df_train['Episode_Length_minutes'].median()\n",
    "\n",
    "# Fill in missing values (2,000 data out of 10,000 data) with the median\n",
    "median_imputed_values = df_nan['Episode_Length_minutes'].fillna(median_value, inplace=False)\n",
    "\n",
    "# Take only the 2,000 data items for evaluation\n",
    "median_imputed_values = median_imputed_values.loc[missing_indices]\n",
    "### -------------------------------------------------------\n",
    "\n",
    "\n",
    "\n",
    "### ---------------- 5. Evaluation ----------------\n",
    "\n",
    "# Evaluate imputation with KNN\n",
    "rmse_knn = np.sqrt(mean_squared_error(original_values, imputed_values))\n",
    "mae_knn = mean_absolute_error(original_values, imputed_values)\n",
    "\n",
    "# Evaluate imputation with the median\n",
    "rmse_median = np.sqrt(mean_squared_error(original_values, median_imputed_values))\n",
    "mae_median = mean_absolute_error(original_values, median_imputed_values)\n",
    "\n",
    "\n",
    "# Display table\n",
    "print(\"\\nüéØ R√©sultats de l'imputation :\\n\")\n",
    "print(\"| Method         |   RMSE   |   MAE   |\")\n",
    "print(\"|-----------------|----------|---------|\")\n",
    "print(f\"| Median        |  {rmse_median:7.2f} |  {mae_median:6.2f} |\")\n",
    "print(f\"| KNN (k=10)      |  {rmse_knn:7.2f} |  {mae_knn:6.2f} |\")\n",
    "### -------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"font-family: Helvetica; line-height: 1.8; color: #000000; text-align: justify\">\n",
    "\n",
    "\n",
    "<span style=\"background-color: #F6CECE; color: #000000;\"><strong>We observe that both methods perform poorly</strong></span>.\n",
    "\n",
    "On <strong>average</strong>, the prediction error for a missing value is around <strong>¬±30 minutes</strong>. Given that episodes last at most <strong>120</strong> minutes, <strong>this is a very large error</strong>.\n",
    "<br>\n",
    "In other words, if we predict that an episode lasts <strong>60</strong> minutes, <strong>its true value could reasonably be anywhere between 30 and 90 minutes</strong>.\n",
    "<br>\n",
    "If this variable is important for predicting a user's listening time, the model‚Äôs performance could be greatly impacted, especially since around <strong>11%</strong> of the values are missing, which is considerable.\n",
    "<br><br>\n",
    "<span style=\"background-color: #F6CECE; color: #000000;\"><strong>Since the median method is slightly more accurate and faster, we will choose it.</strong></span>\n",
    "Thus, we will fill the missing values with the median duration from the training dataset.\n",
    "<br><br>\n",
    "<u><strong>Guest Popularity Percentage:</strong></u>\n",
    "<br><br>\n",
    "<u>Missing values related to guests could mean several things:</u>\n",
    "\n",
    "<li>Either there was an issue during data collection, resulting in 19.6% truly missing values.</li>\n",
    "\n",
    "<li>Or some episodes simply had no guest, and by default, this absence was recorded as missing data.</li>\n",
    "<br>\n",
    "<span style=\"background-color: #F6CECE; color: #000000;\"><strong>In our case, we will assume that episodes with missing guest popularity had no guest.</strong></span>\n",
    "<br>    \n",
    "Our strategy for handling these missing values is <strong>to build two models</strong>:\n",
    "one including the ‚ÄúGuest_Popularity_Percentage‚Äù variable and one excluding it.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------- Fill in missing values -------\n",
    "\n",
    "# Fill in missing values with the median\n",
    "df_train['Episode_Length_minutes'].fillna(df_train['Episode_Length_minutes'].median(), inplace = True)\n",
    "\n",
    "# Remove missing value\n",
    "df_train.dropna(subset=['Number_of_Ads'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the dataset\n",
    "df_train.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='eda_multivariate'></a>\n",
    "# <div style=\" background-color:#162B48; color:white; padding: 12px; line-height: 1.5;\"><strong>5. | EDA Multivariate </strong></div>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def correlation_matrix_3(df, color_0, color_1, color_2, subtitle_1, subtitle_2, subtitle_3):\n",
    "    \n",
    "    # Correlation matrix from -1 to 1 (with 3 colors)\n",
    "    \n",
    "    # If we want a correlation matrix from 0 to 1, we need 2 colors\n",
    "    \n",
    "    # Import the library: import matplotlib.colors as mcolors\n",
    "    \n",
    "    # Highlight text properties\n",
    "    highlight_textprops = [{\"fontsize\":12, \"color\":f'#{color_0}', \"fontname\": \"Cover sans\", \"fontweight\": \"bold\"},\n",
    "                           {\"fontsize\":12, \"color\":f'#33363F', \"fontname\": \"Cover sans\"},\n",
    "                           {\"fontsize\":12, \"color\":f'#{color_0}', \"fontname\": \"Cover sans\", \"fontweight\": \"bold\"},]\n",
    "\n",
    "\n",
    "    # Axis labels color\n",
    "    variable_name_textprops = [{\"fontsize\":8, \"color\":f'#33363F', \"fontname\": \"Cover sans\", \"fontweight\": \"bold\"}]\n",
    "    \n",
    "    # Correlation matrix\n",
    "    correlation_matrix = df.corr(numeric_only=True)\n",
    "\n",
    "    # Figure\n",
    "    fig, ax = plt.subplots(figsize=(12, 8), dpi=500)\n",
    "    \n",
    "\n",
    "    # Remove the upper half of the matrix\n",
    "    mask = np.triu(np.ones_like(df.corr(numeric_only=True), dtype=bool))\n",
    "\n",
    "    \n",
    "    color1 = mcolors.to_rgba(f'#{color_0}')  # Negative value -1\n",
    "    color_intermediate = mcolors.to_rgba(f'#{color_1}')  # Intermediate color (Value 0)\n",
    "    color2 = mcolors.to_rgba(f'#{color_2}')  # Positive value 1\n",
    "\n",
    "    \n",
    "    # Create a custom color palette\n",
    "    n, m = 256, 1\n",
    "    cmap_custom = mcolors.LinearSegmentedColormap.from_list('custom', [color1, color_intermediate, color2], N=n, gamma=m)\n",
    "\n",
    "    # Correlation matrix heatmap\n",
    "    sns.heatmap(correlation_matrix, mask=mask, annot=True, cmap=cmap_custom, fmt=\".2f\", linewidths=0.2, cbar=False,\n",
    "               annot_kws={\"size\": 10})\n",
    "    \n",
    "    \n",
    "    # Horizontal and vertical labels\n",
    "    xy_label = dict(size=6)\n",
    "    yticks, ylabels = plt.yticks()\n",
    "    xticks, xlabels = plt.xticks()\n",
    "    ax.set_xticklabels(xlabels, rotation=0, **xy_label, **variable_name_textprops[0])\n",
    "    ax.set_yticklabels(ylabels, **xy_label, **variable_name_textprops[0])\n",
    "    \n",
    "    \n",
    "    # Add a title to the heatmap axis\n",
    "    ax.set_title('Correlation of Numerical Variables', fontsize=20, fontweight='bold', \n",
    "             fontname='Lisboa Sans OSF', color = \"#33363F\")\n",
    "    \n",
    "    \n",
    "    # Title\n",
    "    # Ajouter du texte √† l'axe avec ax.text()\n",
    "    ax.text(0.40, 0.845, f\"{subtitle_1} {subtitle_2} {subtitle_3}\", \n",
    "        va='bottom', ha='center', fontsize=12, \n",
    "        bbox=dict(facecolor='none', edgecolor='none', boxstyle='round,pad=0.3'), \n",
    "        color='black')  # Vous pouvez ajuster les propri√©t√©s comme la couleur, la taille de police, etc.\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "correlation_matrix_3(df_train,\"243B6E\", \"FFFCF9\", \"EA7F1B\", \"\", \"\", \"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Correlation analysis between numerical variables\n",
    "numeric_cols = ['Episode_Length_minutes', 'Host_Popularity_percentage',\n",
    "                'Guest_Popularity_percentage', 'Number_of_Ads',\n",
    "                'Episode_Number', 'Listening_Time_minutes']\n",
    "\n",
    "# Random sampling\n",
    "df_train_viz = df_train.sample(n=10000, random_state=42)\n",
    "\n",
    "# 2. Interaction: host popularity, genre, and listening time\n",
    "plt.figure(figsize=(14, 8))\n",
    "sns.scatterplot(data=df_train_viz, x='Host_Popularity_percentage', y='Listening_Time_minutes',\n",
    "                hue='Genre', size='Guest_Popularity_percentage', sizes=(20, 200), alpha=0.7)\n",
    "plt.title(\"Host Popularity, Genre, and Listening Time\")\n",
    "plt.xlabel(\"Host Popularity (%)\")\n",
    "plt.ylabel(\"Listening Time (minutes)\")\n",
    "plt.legend(bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# 3. Impact of publication day and number of ads\n",
    "plt.figure(figsize=(14, 8))\n",
    "sns.boxplot(data=df_train_viz, x='Publication_Day', y='Listening_Time_minutes', hue='Number_of_Ads')\n",
    "plt.title(\"Listening Time by Publication Day and Number of Ads\")\n",
    "plt.xlabel(\"Publication Day\")\n",
    "plt.ylabel(\"Listening Time (minutes)\")\n",
    "plt.xticks(rotation=45)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# 4. Listening time / episode length ratio by sentiment and category\n",
    "df_train_viz['Listening_Ratio'] = df_train_viz['Listening_Time_minutes'] / df_train_viz['Episode_Length_minutes']\n",
    "\n",
    "plt.figure(figsize=(16, 10))\n",
    "sns.boxplot(data=df_train_viz, x='Episode_Category', y='Listening_Ratio', hue='Episode_Sentiment')\n",
    "plt.title(\"Listening Ratio by Episode Category and Sentiment\")\n",
    "plt.xlabel(\"Episode Category\")\n",
    "plt.ylabel(\"Listening Time / Episode Length Ratio\")\n",
    "plt.xticks(rotation=45)\n",
    "plt.axhline(y=1, color='red', linestyle='--', alpha=0.7)  # Reference line at 100%\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Define the order of the days of the week\n",
    "day_order = ['Monday', 'Tuesday', 'Wednesday', 'Thursday', 'Friday', 'Saturday', 'Sunday']\n",
    "\n",
    "# Create the pivot table with specific order for Publication_Day\n",
    "pivot_table = df_train_viz.pivot_table(values='Listening_Time_minutes',\n",
    "                                       index='Publication_Day',\n",
    "                                       columns='Episode_Category',\n",
    "                                       aggfunc='mean',\n",
    "                                       observed=True)\n",
    "\n",
    "# Reindex to order the days\n",
    "pivot_table = pivot_table.reindex(day_order)\n",
    "\n",
    "# Create the heatmap\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.heatmap(pivot_table, annot=True, cmap='YlGnBu', fmt='.1f', linewidths=0.5)\n",
    "plt.title(\"Average Listening Time by Day and Category\")\n",
    "plt.xlabel(\"Category\")\n",
    "plt.ylabel(\"Publication Day\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='preprocessing'></a>\n",
    "# <div style=\" background-color:#162B48; color:white; padding: 12px; line-height: 1.5;\"><strong>6. | Preprocessing</strong></div>\n",
    "\n",
    "<div style=\"font-family: Helvetica; line-height: 1.8; color: #000000; text-align: justify\">\n",
    "\n",
    "<span style=\"background-color: #F6CECE; color: #000000;\"><strong>Preprocessing consists of transforming the data to facilitate model training and improve its performance.</strong></span><br> <u>It is divided into three main steps:</u>\n",
    "\n",
    "<li>Feature Engineering</li>\n",
    "\n",
    "<li>Pipeline</li>\n",
    "\n",
    "<li>Data Splitting</li>\n",
    "<br><br>\n",
    "In our project, <strong>we aim to train two models</strong>: one that includes the ‚ÄúGuest_Popularity_Percentage‚Äù variable and another without it.\n",
    "<br>\n",
    "For now, these two models will be developed separately. Once their training is complete, <span style=\"background-color: #F6CECE; color: #000000;\"><strong>we will implement a routing pipeline (Router) to dynamically select which model to use depending on the context</strong></span>, thereby simplifying deployment to production.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <div style=\" background-color: #D72729; color:white; padding: 10px; line-height: 1.5;\"><strong>6.1 | Import libraries üìö</strong></div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Preprocessing ---\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import FunctionTransformer, StandardScaler\n",
    "from sklearn.base import BaseEstimator, TransformerMixin, RegressorMixin\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <div style=\" background-color: #D72729; color:white; padding: 10px; line-height: 1.5;\"><strong>6.2 | Feature Engineering</strong></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <div style=\" background-color: #D72729; color:white; padding: 10px; line-height: 1.5;\"><strong>6.3 | Pipeline</strong></div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----- Create a transform for a new variable -----\n",
    "\n",
    "def add_episode_category_column(df):\n",
    "    \n",
    "    # Convert to category\n",
    "    df = df.copy()\n",
    "    df[\"Episode_Title\"] = df[\"Episode_Title\"].astype(\"category\")\n",
    "    \n",
    "    # Extract episode number\n",
    "    df['Episode_Number'] = df['Episode_Title'].apply(lambda x: int(re.search(r'\\d+', x).group()))\n",
    "    \n",
    "    # Categorize episodes\n",
    "    df['Episode_Category'] = pd.cut(df['Episode_Number'], \n",
    "                                    bins=[0, 25, 50, 75, 100], \n",
    "                                    labels=['Start', 'Early Middle', 'Late Middle', 'End'], \n",
    "                                    right=True)\n",
    "    return df\n",
    "\n",
    "episode_category_transformer = FunctionTransformer(add_episode_category_column, validate=False)\n",
    "# --------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----- Handling outliers -----\n",
    "\n",
    "def outlier_features(df):\n",
    "    df = df.copy()\n",
    "    \n",
    "    if 'Episode_Length_minutes' in df.columns:\n",
    "        df['Episode_Length_minutes'] = df['Episode_Length_minutes'].clip(upper=119.99)\n",
    "        \n",
    "    if 'Host_Popularity_percentage' in df.columns:\n",
    "        df['Host_Popularity_percentage'] = df['Host_Popularity_percentage'].clip(upper=100)\n",
    "        \n",
    "    if 'Guest_Popularity_percentage' in df.columns:\n",
    "        df['Guest_Popularity_percentage'] = df['Guest_Popularity_percentage'].clip(upper=100)\n",
    "        \n",
    "    if 'Number_of_Ads' in df.columns:\n",
    "        df['Number_of_Ads'] = df['Number_of_Ads'].clip(upper=3)\n",
    "    \n",
    "    return df\n",
    "\n",
    "outlier_transformer = FunctionTransformer(outlier_features, validate=False)\n",
    "# --------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----- Create a transform for missing values -----\n",
    "\n",
    "def fill_missing_features(df):\n",
    "    df = df.copy()\n",
    "    \n",
    "    median_val = df['Episode_Length_minutes'].median()\n",
    "    df['Episode_Length_minutes'] = df['Episode_Length_minutes'].fillna(median_val)\n",
    "    \n",
    "    return df\n",
    "\n",
    "fill_missing_transformer = FunctionTransformer(fill_missing_features, validate=False)\n",
    "# --------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----- Create a transform to delete selected variables -----\n",
    "\n",
    "def remove_columns(df):\n",
    "    cols_to_drop = ['Podcast_Name', 'Episode_Title', 'Episode_Number']\n",
    "    existing_cols_to_drop = [col for col in cols_to_drop if col in df.columns]\n",
    "    df = df.drop(columns=existing_cols_to_drop)\n",
    "    return df\n",
    "\n",
    "remove_columns_transformer = FunctionTransformer(remove_columns, validate=False)\n",
    "# --------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----- Create an encoding transformer -----\n",
    "\n",
    "def apply_get_dummies(X):\n",
    "    return pd.get_dummies(X, drop_first=True)\n",
    "\n",
    "encoding = FunctionTransformer(apply_get_dummies, validate=False)\n",
    "# --------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----- Create a transformer to standardize quantitative variables -----\n",
    "\n",
    "class SelectiveStandardScaler(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self):\n",
    "        self.scaler = StandardScaler()\n",
    "    \n",
    "    def fit(self, X, y=None):\n",
    "        # Automatically select numeric columns\n",
    "        self.continuous_columns = X.select_dtypes(include=['float64', 'int64']).columns\n",
    "        self.scaler.fit(X[self.continuous_columns])\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X):\n",
    "        # Apply scaler only to continuous columns\n",
    "        X_scaled = X.copy()\n",
    "        X_scaled[self.continuous_columns] = self.scaler.transform(X[self.continuous_columns])\n",
    "        return X_scaled\n",
    "# --------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----- Preprocessing Pipeline -----\n",
    "\n",
    "preprocessing_pipeline = Pipeline([\n",
    "    \n",
    "    (\"episode_category\", episode_category_transformer), # Add \"Episode_Category\"\n",
    "    ('outlier', outlier_transformer),                   # Clean outlier\n",
    "    ('fill_missing', fill_missing_transformer),         # Fill missing values\n",
    "    ('remove_columns', remove_columns_transformer),     # Remove columns\n",
    "    (\"encoder\", encoding),                              # Encoding\n",
    "    ('scaler', SelectiveStandardScaler())               # Standardisation\n",
    "\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# ----- Testing our pipeline -----\n",
    "\n",
    "data = {\n",
    "    \"Podcast_Name\" : [\"Broad\"]*5,\n",
    "    \"Episode_Title\" : [\"Episode 12\", \"Episode 95\", \"Episode 50\", \"Episode 75\", \"Episode 35\"],\n",
    "    'Episode_Length_minutes': [130, 150, 2, 3, 60],\n",
    "    'Genre' : [\"True Crime\", \"Comedy\", \"Education\", \"Technology\", \"Health\"],\n",
    "    'Host_Popularity_percentage': [30, 150, 2, 3, 600],\n",
    "    \"Publication_Day\" : [\"Thursday\", \"Saturday\", \"Tuesday\", \"Monday\", \"Monday\"],\n",
    "    'Publication_Time': [\"Night\", \"Afternoon\", \"Evening\", \"Morning\", \"Afternoon\"],\n",
    "    \"Guest_Popularity_percentage\" : [30, 150, 2, 3, 600],\n",
    "    \"Number_of_Ads\" : [3, 150, 2, 3, 4],\n",
    "    \"Episode_Sentiment\" : [\"Positive\", \"Negative\", \"Neutral\", \"Negative\", \"Positive\"]\n",
    "}\n",
    "\n",
    "data = pd.DataFrame(data)\n",
    "\n",
    "processed_data = preprocessing_pipeline.fit_transform(data)\n",
    "\n",
    "print(\"Created data :\")\n",
    "print(data.head())\n",
    "print(\"\\n \\n \\n\")\n",
    "print(\"-\"*100)\n",
    "print(\"\\nData after transformation :\")\n",
    "print(processed_data.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <div style=\" background-color: #D72729; color:white; padding: 10px; line-height: 1.5;\"><strong>6.4 | Data separation</strong></div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- DataFrame with non-missing Guest_Popularity_percentage ---\n",
    "df_with_guest_pop = df_train[df_train['Guest_Popularity_percentage'].notna()].copy()\n",
    "\n",
    "# --- DataFrame with missing Guest_Popularity_percentage ---\n",
    "df_without_guest_pop = df_train[df_train['Guest_Popularity_percentage'].isna()].copy()\n",
    "df_without_guest_pop = df_without_guest_pop.drop(columns=['Guest_Popularity_percentage'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Take a sample of 20,000 samples ---\n",
    "\n",
    "df_with_guest_pop_sample = df_with_guest_pop.sample(n=20_000, random_state=42)\n",
    "\n",
    "df_without_guest_pop_sample = df_without_guest_pop.sample(n=20_000, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----- Separating vector and matrix -----\n",
    "\n",
    "X_with_gp = df_with_guest_pop_sample.drop(columns = 'Listening_Time_minutes')\n",
    "y_with_gp = df_with_guest_pop_sample['Listening_Time_minutes']\n",
    "\n",
    "X_without_gp = df_without_guest_pop_sample.drop(columns = 'Listening_Time_minutes')\n",
    "y_without_gp = df_without_guest_pop_sample['Listening_Time_minutes']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----- Split into train and test sets for two models -----\n",
    "\n",
    "# With Guest_Popularity_Percentange\n",
    "X_with_gp_train, X_with_gp_test, y_with_gp_train, y_with_gp_test = train_test_split(\n",
    "    X_with_gp, y_with_gp, test_size=0.30, random_state=42\n",
    ")\n",
    "\n",
    "# Without Guest_Popularity_Percentange\n",
    "X_without_gp_train, X_without_gp_test, y_without_gp_train, y_without_gp_test = train_test_split(\n",
    "    X_without_gp, y_without_gp, test_size=0.30, random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='models'></a>\n",
    "# <div style=\" background-color:#162B48; color:white; padding: 12px; line-height: 1.5;\"><strong>7. | Models</strong></div>\n",
    "\n",
    "<div style=\"font-family: Helvetica; line-height: 1.8; color: #000000; text-align: justify\">\n",
    "    \n",
    "In this section, we will <span style=\"background-color: #F6CECE; color: #000000;\"><strong>train several models</strong></span> to identify the one that offers the best performance, as well as the optimal hyperparameters.\n",
    "<br>\n",
    "<u>To do so, we will use two search methods:</u>\n",
    "\n",
    "<li>GridSearchCV</li>\n",
    "\n",
    "<li>Optuna</li>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <div style=\" background-color: #D72729; color:white; padding: 10px; line-height: 1.5;\"><strong>7.1 | Import libraries üìö</strong></div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# --- Installing Libraries ---\n",
    "!pip install xgboost\n",
    "!pip install optuna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----- Preprocessing -----\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "\n",
    "# ----- Hyperparameters -----\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "import optuna\n",
    "\n",
    "# ----- Models -----\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from xgboost import XGBRegressor\n",
    "\n",
    "# ----- Metrics -----\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <div style=\" background-color: #D72729; color:white; padding: 10px; line-height: 1.5;\"><strong>7.2 | Linear Regression</strong></div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --------------- Train model n¬∞01 with Guest Popularity using linear regression ---------------\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "# ----- Pipeline with Linear Regression -----\n",
    "\n",
    "lr_pipeline_with_gp = make_pipeline(\n",
    "    preprocessing_pipeline,\n",
    "    LinearRegression()\n",
    ")\n",
    "\n",
    "# ----- Hyperparameters -----\n",
    "\n",
    "param_lr_with_gp = {\n",
    "    'linearregression__fit_intercept': [True, False],\n",
    "}\n",
    "\n",
    "# ----- GridSearchCV -----\n",
    "\n",
    "grid_search_lr_with_gp = GridSearchCV(\n",
    "    lr_pipeline_with_gp,\n",
    "    param_lr_with_gp,\n",
    "    cv=5,\n",
    "    scoring='neg_root_mean_squared_error',\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "grid_search_lr_with_gp.fit(X_with_gp_train, y_with_gp_train)\n",
    "\n",
    "# ----- Show the best hyperparameters -----\n",
    "\n",
    "pd.DataFrame(grid_search_lr_with_gp.cv_results_).sort_values(\"rank_test_score\").head()\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --------------- Train model n¬∞02 without Guest Popularity using linear regression ---------------\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "# ----- Pipeline with Linear Regression -----\n",
    "\n",
    "lr_pipeline_without_gp = make_pipeline(\n",
    "    preprocessing_pipeline,\n",
    "    LinearRegression()\n",
    ")\n",
    "\n",
    "# ----- Hyperparameters -----\n",
    "\n",
    "param_lr_without_gp = {\n",
    "    'linearregression__fit_intercept': [True, False],\n",
    "}\n",
    "\n",
    "# ----- GridSearchCV -----\n",
    "\n",
    "grid_search_lr_without_gp = GridSearchCV(\n",
    "    lr_pipeline_without_gp,\n",
    "    param_lr_without_gp,\n",
    "    cv=5,\n",
    "    scoring='neg_root_mean_squared_error',\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "grid_search_lr_without_gp.fit(X_without_gp_train, y_without_gp_train)\n",
    "\n",
    "# ----- Show the best hyperparameters -----\n",
    "\n",
    "pd.DataFrame(grid_search_lr_without_gp.cv_results_).sort_values(\"rank_test_score\").head()\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <div style=\" background-color: #D72729; color:white; padding: 10px; line-height: 1.5;\"><strong>7.3 | Random Forest</strong></div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --------------- Train model n¬∞01 with Guest Popularity using RandomForest ---------------\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "# ----- Pipeline with RandomForest Regressor -----\n",
    "\n",
    "rf_pipeline_with_gp = make_pipeline(\n",
    "    preprocessing_pipeline,\n",
    "    RandomForestRegressor(random_state = 450)\n",
    ")\n",
    "\n",
    "# ----- Hyperparameters -----\n",
    "\n",
    "param_rf_with_gp = {\n",
    "    'randomforestregressor__n_estimators': [100, 200, 300],\n",
    "    'randomforestregressor__max_depth': [2, 5, 7, 15],      \n",
    "    'randomforestregressor__min_samples_split': [2, 5, 10],           \n",
    "    'randomforestregressor__min_samples_leaf': [1, 4, 7],            \n",
    "}\n",
    "\n",
    "# ----- GridSearchCv -----\n",
    "\n",
    "grid_search_rf_with_gp = GridSearchCV(rf_pipeline_with_gp, \n",
    "                                      param_rf_with_gp, \n",
    "                                      cv = 5, \n",
    "                                      scoring='neg_root_mean_squared_error', \n",
    "                                      n_jobs=-1)\n",
    "\n",
    "grid_search_rf_with_gp.fit(X_with_gp_train, y_with_gp_train)\n",
    "\n",
    "# ----- Show the best hyperparameters -----\n",
    "\n",
    "pd.DataFrame(grid_search_rf_with_gp.cv_results_).sort_values(\"rank_test_score\").head()\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --------------- Train model n¬∞02 without Guest Popularity using RandomForest ---------------\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "# ----- Pipeline with RandomForest Regressor -----\n",
    "\n",
    "rf_pipeline_without_gp = make_pipeline(\n",
    "    preprocessing_pipeline,\n",
    "    RandomForestRegressor(random_state = 450)\n",
    ")\n",
    "\n",
    "# ----- Hyperparameters -----\n",
    "\n",
    "param_rf_without_gp = {\n",
    "    'randomforestregressor__n_estimators': [100, 200, 300],\n",
    "    'randomforestregressor__max_depth': [2, 5, 7, 15],  \n",
    "    'randomforestregressor__min_samples_split': [2, 5, 10], \n",
    "    'randomforestregressor__min_samples_leaf': [1, 4, 7], \n",
    "}\n",
    "\n",
    "# ----- GridSearchCv -----\n",
    "\n",
    "grid_search_rf_without_gp = GridSearchCV(rf_pipeline_without_gp, \n",
    "                                      param_rf_without_gp, \n",
    "                                      cv = 5, \n",
    "                                      scoring='neg_root_mean_squared_error', \n",
    "                                      n_jobs=-1)\n",
    "\n",
    "grid_search_rf_without_gp.fit(X_without_gp_train, y_without_gp_train)\n",
    "\n",
    "# ----- Show the best hyperparameters -----\n",
    "\n",
    "pd.DataFrame(grid_search_rf_without_gp.cv_results_).sort_values(\"rank_test_score\").head()\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <div style=\" background-color: #D72729; color:white; padding: 10px; line-height: 1.5;\"><strong>7.4 | XGBoost (Optuna)</strong></div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# --------------- Train model n¬∞01 with Guest Popularity using XGBoost and Optuna ---------------\n",
    "\"\"\"\n",
    "def objective(trial):\n",
    "    \n",
    "    # Hyperparameters\n",
    "    params = {\n",
    "        'n_estimators': trial.suggest_int('n_estimators', 100, 500),\n",
    "        'max_depth': trial.suggest_int('max_depth', 3, 15),\n",
    "        'learning_rate': trial.suggest_float('learning_rate', 0.001, 0.3, log=True),\n",
    "        'subsample': trial.suggest_float('subsample', 0.4, 1.0),\n",
    "        'colsample_bytree': trial.suggest_float('colsample_bytree', 0.4, 1.0)\n",
    "    }\n",
    "\n",
    "    # Pipeline\n",
    "    model = make_pipeline(\n",
    "        preprocessing_pipeline,\n",
    "        XGBRegressor(\n",
    "            objective=\"reg:squarederror\",\n",
    "            random_state=42,\n",
    "            n_jobs=-1,\n",
    "            **params\n",
    "        )\n",
    "    )\n",
    "\n",
    "    # Cross-validation with RMSE\n",
    "    scores = cross_val_score(\n",
    "        model,\n",
    "        X_with_gp_train,\n",
    "        y_with_gp_train,\n",
    "        scoring=\"neg_root_mean_squared_error\",\n",
    "        cv=5,\n",
    "        n_jobs=-1\n",
    "    )\n",
    "\n",
    "    return np.mean(scores)\n",
    "\n",
    "# Create and lunch Optuna\n",
    "study = optuna.create_study(direction=\"maximize\") \n",
    "study.optimize(objective, n_trials=100)\n",
    "\n",
    "# Best parameters\n",
    "print(\"Best trial:\")\n",
    "print(study.best_trial)\n",
    "best_params_with_gp = study.best_trial.params\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --------------- Train model n¬∞02 without Guest Popularity using XGBoost and Optuna ---------------\n",
    "\"\"\"\n",
    "def objective(trial):\n",
    "    \n",
    "    # Hyperparameters\n",
    "    params = {\n",
    "        'n_estimators': trial.suggest_int('n_estimators', 100, 500),\n",
    "        'max_depth': trial.suggest_int('max_depth', 3, 15),\n",
    "        'learning_rate': trial.suggest_float('learning_rate', 0.001, 0.3, log=True),\n",
    "        'subsample': trial.suggest_float('subsample', 0.4, 1.0),\n",
    "        'colsample_bytree': trial.suggest_float('colsample_bytree', 0.4, 1.0)\n",
    "    }\n",
    "\n",
    "    # Pipeline\n",
    "    model = make_pipeline(\n",
    "        preprocessing_pipeline,\n",
    "        XGBRegressor(\n",
    "            objective=\"reg:squarederror\",\n",
    "            random_state=42,\n",
    "            n_jobs=-1,\n",
    "            **params\n",
    "        )\n",
    "    )\n",
    "\n",
    "    # Cross-validation with RMSE\n",
    "    scores = cross_val_score(\n",
    "        model,\n",
    "        X_without_gp_train,\n",
    "        y_without_gp_train,\n",
    "        scoring=\"neg_root_mean_squared_error\",\n",
    "        cv=5,\n",
    "        n_jobs=-1\n",
    "    )\n",
    "\n",
    "    return np.mean(scores)\n",
    "\n",
    "# Create and lunch Optuna\n",
    "study = optuna.create_study(direction=\"maximize\")\n",
    "study.optimize(objective, n_trials=100)\n",
    "\n",
    "# Best parameters\n",
    "print(\"Best trial:\")\n",
    "print(study.best_trial)\n",
    "best_params_without_gp = study.best_trial.params\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <div style=\" background-color: #D72729; color:white; padding: 10px; line-height: 1.5;\"><strong>7.5 | Final Model</strong></div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------------- Train the entire train set --------------------\n",
    "\n",
    "# ----- Separating vector and matrix -----\n",
    "\n",
    "X_with_gp = df_with_guest_pop.drop(columns = 'Listening_Time_minutes')\n",
    "y_with_gp = df_with_guest_pop['Listening_Time_minutes']\n",
    "\n",
    "X_without_gp = df_without_guest_pop.drop(columns = 'Listening_Time_minutes')\n",
    "y_without_gp = df_without_guest_pop['Listening_Time_minutes']\n",
    "\n",
    "\n",
    "# ----- Split into train and test sets for two models -----\n",
    "\n",
    "# With Guest_Popularity_Percentange (Model n¬∞01)\n",
    "X_with_gp_train, X_with_gp_test, y_with_gp_train, y_with_gp_test = train_test_split(\n",
    "    X_with_gp, y_with_gp, test_size=0.30, random_state=42\n",
    ")\n",
    "\n",
    "# Without Guest_Popularity_Percentange (Model n¬∞02)\n",
    "X_without_gp_train, X_without_gp_test, y_without_gp_train, y_without_gp_test = train_test_split(\n",
    "    X_without_gp, y_without_gp, test_size=0.30, random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------- Pipeline with the final model n¬∞01 (with Guest Popularity) ----------\n",
    "\n",
    "# Best hyperparameters\n",
    "final_param_xgb_with_gp = {\n",
    "    'n_estimators': 425,\n",
    "    'max_depth': 4,\n",
    "    'learning_rate': 0.01359661519238633,\n",
    "    'subsample': 0.4008805073963276,\n",
    "    'colsample_bytree': 0.8325187832312463,\n",
    "}\n",
    "\n",
    "# Final pipeline\n",
    "pipeline_with_gp = make_pipeline(\n",
    "    preprocessing_pipeline,\n",
    "    XGBRegressor(random_state = 42, **final_param_xgb_with_gp)\n",
    ")\n",
    "\n",
    "\n",
    "# ---------- Pipeline with the final model n¬∞02 (without Guest Popularity) ----------\n",
    "\n",
    "# Best hyperparameters\n",
    "final_param_xgb_without_gp = {\n",
    "    'n_estimators': 339,\n",
    "    'max_depth': 4,\n",
    "    'learning_rate': 0.01530999750231462,\n",
    "    'subsample': 0.40013910962061794,\n",
    "    'colsample_bytree': 0.9824077721256953,\n",
    "}\n",
    "\n",
    "# Final pipeline\n",
    "pipeline_without_gp = make_pipeline(\n",
    "    preprocessing_pipeline,\n",
    "    XGBRegressor(random_state = 450, **final_param_xgb_without_gp)\n",
    ")\n",
    "\n",
    "\n",
    "# ---------- Train the final models on the entire train set without cross validation ----------\n",
    "\n",
    "# With Guest Popularity (Model n¬∞01)\n",
    "pipeline_with_gp.fit(X_with_gp_train, y_with_gp_train)\n",
    "\n",
    "\n",
    "# Without Guest Popularity (Model n¬∞02)\n",
    "pipeline_without_gp.fit(X_without_gp_train, y_without_gp_train)\n",
    "\n",
    "\n",
    "# ---------- Prediction ----------\n",
    "\n",
    "y_pred_with_gp = pipeline_with_gp.predict(X_with_gp_test)\n",
    "y_pred_without_gp = pipeline_without_gp.predict(X_without_gp_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <div style=\" background-color: #D72729; color:white; padding: 10px; line-height: 1.5;\"><strong>7.6 | Evaluation</strong></div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------ Residual ------\n",
    "residuals_with_gp = y_pred_with_gp - y_with_gp_test\n",
    "residuals_with_gp_abs = np.abs(residuals_with_gp)\n",
    "\n",
    "# ------ Find the interval where 95% of errors are included ------\n",
    "X_95_gp = 30\n",
    "percentage_gp = 3.88\n",
    "\n",
    "while percentage_gp <= 5 :\n",
    "    X_95_gp -= 0.01\n",
    "    percentage_gp = np.mean(residuals_with_gp_abs >= X_95_gp) * 100\n",
    "    \n",
    "print(np.round(X_95_gp, 3), np.round(percentage_gp, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 2, figsize=(14, 6), dpi = 300)\n",
    "\n",
    "\n",
    "# ------------------------------------ Scatterplot of residues ------------------------------------\n",
    "axes[0].scatter(y_with_gp_test, residuals_with_gp, alpha=0.02, color = \"#0070C0\")\n",
    "axes[0].axhline(0, color=\"red\", linestyle=\"--\", linewidth=2, alpha = 0.5)\n",
    "\n",
    "\n",
    "# Title\n",
    "highlight_textprops = {\"fontsize\":14, \"color\":'#262626', \"fontname\": \"Roboto\", \"fontweight\": \"semibold\"}\n",
    "axes[0].set_title(\"Distribution of errors based on \\nthe actual listening duration of a podcast\", \n",
    "                  pad=20,\n",
    "                  **highlight_textprops)\n",
    "\n",
    "# Define x and y axis name\n",
    "highlight_textprops1 = [{\"fontsize\":12, \"color\":'#262626', \"fontname\": \"Roboto\", \"fontweight\": \"semibold\"}]\n",
    "axes[0].set_xlabel(f\"Real podcast listening time\", **highlight_textprops1[-1])\n",
    "axes[0].set_ylabel(f\"Errors\", **highlight_textprops1[-1])\n",
    "axes[0].yaxis.labelpad = 20\n",
    "axes[0].xaxis.labelpad = 20\n",
    "\n",
    "# Remove top right frame\n",
    "axes[0].spines['top'].set_visible(False)\n",
    "axes[0].spines['right'].set_visible(False)\n",
    "    \n",
    "# Add a frame at bottom left\n",
    "axes[0].spines['bottom'].set_linewidth(1.3)\n",
    "axes[0].spines['bottom'].set_color('#CAC9CD')\n",
    "axes[0].spines['left'].set_linewidth(1.3)\n",
    "axes[0].spines['left'].set_color('#CAC9CD')\n",
    "    \n",
    "# Add grids\n",
    "axes[0].grid(axis='x', which='major', alpha=0.5, linestyle='dotted', zorder=1)\n",
    "axes[0].grid(axis='y', alpha=0, zorder=2)\n",
    "       \n",
    "# Change the color of the bars on the x axis\n",
    "axes[0].tick_params(axis='x', colors='#CAC9CD', width=1.3)\n",
    "axes[0].tick_params(axis='y', colors='#CAC9CD', width=1.3)\n",
    "      \n",
    "# Change the color of the bar values on the x axis\n",
    "for tick in axes[0].get_xticklabels():\n",
    "    tick.set_color('#202020') \n",
    "\n",
    "# Change color of y-axis scale bar values\n",
    "for tick in axes[0].get_yticklabels():\n",
    "    tick.set_color('#202020') \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# ------------------------------------ KDE of residues ------------------------------------\n",
    "sns.kdeplot(residuals_with_gp, ax=axes[1], fill=True, alpha = 0.3)\n",
    "    \n",
    "# Title\n",
    "highlight_textprops = {\"fontsize\":14, \"color\":'#262626', \"fontname\": \"Roboto\", \"fontweight\": \"semibold\"}\n",
    "axes[1].set_title(\"Error distribution\", \n",
    "                  pad=20,\n",
    "                  **highlight_textprops)\n",
    "    \n",
    "# D√©finir le nom de l'axe des x et y\n",
    "highlight_textprops1 = [{\"fontsize\":12, \"color\":'#262626', \"fontname\": \"Roboto\", \"fontweight\": \"semibold\"}]\n",
    "axes[1].set_xlabel(f\"Errors\", **highlight_textprops1[-1])\n",
    "axes[1].set_ylabel(f\"Density\", **highlight_textprops1[-1])    \n",
    "axes[1].xaxis.labelpad = 20\n",
    "axes[1].yaxis.labelpad = 20\n",
    "\n",
    "\n",
    "# Remove top right frame\n",
    "axes[1].spines['top'].set_visible(False)\n",
    "axes[1].spines['right'].set_visible(False)\n",
    "\n",
    "# Add a frame at bottom left\n",
    "axes[1].spines['bottom'].set_linewidth(1.2)\n",
    "axes[1].spines['bottom'].set_color('#CAC9CD')\n",
    "axes[1].spines['left'].set_linewidth(1.2)\n",
    "axes[1].spines['left'].set_color('#CAC9CD')\n",
    "\n",
    "# Add grids\n",
    "axes[1].grid(axis='x', which='major', alpha=0.75, linestyle='dotted', zorder=1)\n",
    "axes[1].grid(axis='y', alpha=0, zorder=2)\n",
    "\n",
    "# Change the color of the bars on the x axis\n",
    "axes[1].tick_params(axis='x', colors='#CAC9CD', width=1.2)\n",
    "axes[1].tick_params(axis='y', colors='#CAC9CD', width=1.2)\n",
    "\n",
    "# Change the color of the bar values on the x axis\n",
    "for tick in axes[1].get_xticklabels():\n",
    "    tick.set_color('#202020') \n",
    "\n",
    "# Change color of y-axis scale bar values\n",
    "for tick in axes[1].get_yticklabels():\n",
    "    tick.set_color('#202020') \n",
    "\n",
    "# Add a general title for all graphics\n",
    "fig.suptitle(\"Model n¬∞01: Evaluation Performance Report (with)\", fontsize=22, \n",
    "             fontweight='semibold', \n",
    "             fontname=\"Roboto\",\n",
    "             y=1.02)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.subplots_adjust(hspace=0.45) \n",
    "plt.subplots_adjust(wspace=0.25)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------ Residual ------\n",
    "residuals_without_gp = y_pred_without_gp - y_without_gp_test\n",
    "residuals_without_gp_abs = np.abs(residuals_without_gp)\n",
    "\n",
    "# ------ Find the interval where 95% of errors are included ------\n",
    "X_95 = 30\n",
    "percentage = 3.88\n",
    "\n",
    "while percentage <= 5 :\n",
    "    X_95 -= 0.01\n",
    "    percentage = np.mean(residuals_without_gp_abs >= X_95) * 100\n",
    "    \n",
    "print(np.round(X_95, 3), np.round(percentage, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 2, figsize=(14, 6), dpi = 300)\n",
    "\n",
    "\n",
    "# ------------------------------------ Scatterplot of residues ------------------------------------\n",
    "axes[0].scatter(y_without_gp_test, residuals_without_gp, alpha=0.07, color = \"#0070C0\")\n",
    "axes[0].axhline(0, color=\"red\", linestyle=\"--\", linewidth=2, alpha = 0.5)\n",
    "\n",
    "\n",
    "# Title\n",
    "highlight_textprops = {\"fontsize\":14, \"color\":'#262626', \"fontname\": \"Roboto\", \"fontweight\": \"semibold\"}\n",
    "axes[0].set_title(\"Distribution of errors based on \\nthe actual listening duration of a podcast\", \n",
    "                  pad=20,\n",
    "                  **highlight_textprops)\n",
    "\n",
    "# Define x and y axis name\n",
    "highlight_textprops1 = [{\"fontsize\":12, \"color\":'#262626', \"fontname\": \"Roboto\", \"fontweight\": \"semibold\"}]\n",
    "axes[0].set_xlabel(f\"Real podcast listening time\", **highlight_textprops1[-1])\n",
    "axes[0].set_ylabel(f\"Errors\", **highlight_textprops1[-1])\n",
    "axes[0].yaxis.labelpad = 20\n",
    "axes[0].xaxis.labelpad = 20\n",
    "\n",
    "# Remove top right frame\n",
    "axes[0].spines['top'].set_visible(False)\n",
    "axes[0].spines['right'].set_visible(False)\n",
    "    \n",
    "# Add a frame at bottom left\n",
    "axes[0].spines['bottom'].set_linewidth(1.3)\n",
    "axes[0].spines['bottom'].set_color('#CAC9CD')\n",
    "axes[0].spines['left'].set_linewidth(1.3)\n",
    "axes[0].spines['left'].set_color('#CAC9CD')\n",
    "    \n",
    "# Add grids\n",
    "axes[0].grid(axis='x', which='major', alpha=0.5, linestyle='dotted', zorder=1)\n",
    "axes[0].grid(axis='y', alpha=0, zorder=2)\n",
    "       \n",
    "# Change the color of the bars on the x axis\n",
    "axes[0].tick_params(axis='x', colors='#CAC9CD', width=1.3)\n",
    "axes[0].tick_params(axis='y', colors='#CAC9CD', width=1.3)\n",
    "      \n",
    "# Change the color of the bar values on the x axis\n",
    "for tick in axes[0].get_xticklabels():\n",
    "    tick.set_color('#202020') \n",
    "\n",
    "# Change color of y-axis scale bar values\n",
    "for tick in axes[0].get_yticklabels():\n",
    "    tick.set_color('#202020') \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# ------------------------------------ KDE of residues ------------------------------------\n",
    "sns.kdeplot(residuals_without_gp, ax=axes[1], fill=True, alpha = 0.3)\n",
    "    \n",
    "# Title\n",
    "highlight_textprops = {\"fontsize\":14, \"color\":'#262626', \"fontname\": \"Roboto\", \"fontweight\": \"semibold\"}\n",
    "axes[1].set_title(\"Error distribution\", \n",
    "                  pad=20,\n",
    "                  **highlight_textprops)\n",
    "    \n",
    "# D√©finir le nom de l'axe des x et y\n",
    "highlight_textprops1 = [{\"fontsize\":12, \"color\":'#262626', \"fontname\": \"Roboto\", \"fontweight\": \"semibold\"}]\n",
    "axes[1].set_xlabel(f\"Errors\", **highlight_textprops1[-1])\n",
    "axes[1].set_ylabel(f\"Density\", **highlight_textprops1[-1])    \n",
    "axes[1].xaxis.labelpad = 20\n",
    "axes[1].yaxis.labelpad = 20\n",
    "\n",
    "\n",
    "# Remove top right frame\n",
    "axes[1].spines['top'].set_visible(False)\n",
    "axes[1].spines['right'].set_visible(False)\n",
    "\n",
    "# Add a frame at bottom left\n",
    "axes[1].spines['bottom'].set_linewidth(1.2)\n",
    "axes[1].spines['bottom'].set_color('#CAC9CD')\n",
    "axes[1].spines['left'].set_linewidth(1.2)\n",
    "axes[1].spines['left'].set_color('#CAC9CD')\n",
    "\n",
    "# Add grids\n",
    "axes[1].grid(axis='x', which='major', alpha=0.75, linestyle='dotted', zorder=1)\n",
    "axes[1].grid(axis='y', alpha=0, zorder=2)\n",
    "\n",
    "# Change the color of the bars on the x axis\n",
    "axes[1].tick_params(axis='x', colors='#CAC9CD', width=1.2)\n",
    "axes[1].tick_params(axis='y', colors='#CAC9CD', width=1.2)\n",
    "\n",
    "# Change the color of the bar values on the x axis\n",
    "for tick in axes[1].get_xticklabels():\n",
    "    tick.set_color('#202020') \n",
    "\n",
    "# Change color of y-axis scale bar values\n",
    "for tick in axes[1].get_yticklabels():\n",
    "    tick.set_color('#202020') \n",
    "\n",
    "# Add a general title for all graphics\n",
    "fig.suptitle(\"Model n¬∞02: Evaluation Performance Report (without)\", fontsize=22, \n",
    "             fontweight='semibold', \n",
    "             fontname=\"Roboto\",\n",
    "             y=1.02)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.subplots_adjust(hspace=0.45) \n",
    "plt.subplots_adjust(wspace=0.25)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------------------------- Evaluation --------------------------------\n",
    "\n",
    "\n",
    "# --- With Guest Popularity ---\n",
    "# RMSE\n",
    "rmse_with_gp = np.sqrt(np.mean((y_pred_with_gp - y_with_gp_test)**2))\n",
    "rmse_with_gp\n",
    "\n",
    "# MAE\n",
    "mae_with_gp = np.mean(np.abs(y_pred_with_gp - y_with_gp_test))\n",
    "mae_with_gp\n",
    "\n",
    "# R2\n",
    "r2_with_gp = ((np.var(y_with_gp_test) - np.var(y_with_gp_test - y_pred_with_gp)) / np.var(y_with_gp_test)) * 100\n",
    "r2_with_gp\n",
    "\n",
    "\n",
    "# --- Without Guest Popularity ---\n",
    "# RMSE\n",
    "rmse_without_gp = np.sqrt(np.mean((y_pred_without_gp - y_without_gp_test)**2))\n",
    "rmse_without_gp\n",
    "\n",
    "# MAE\n",
    "mae_without_gp = np.mean(np.abs(y_pred_without_gp - y_without_gp_test))\n",
    "mae_without_gp\n",
    "\n",
    "# R2\n",
    "r2_without_gp = ((np.var(y_without_gp_test) - np.var(y_without_gp_test - y_pred_without_gp)) / np.var(y_without_gp_test)) * 100\n",
    "r2_without_gp\n",
    "\n",
    "\n",
    "# --- Table ---\n",
    "results = pd.DataFrame({\n",
    "    \"Model\": [\"With Guest Popularity\", \"Without Guest Popularity\"],\n",
    "    \"RMSE\": [rmse_with_gp, rmse_without_gp],\n",
    "    \"MAE\": [mae_with_gp, mae_without_gp],\n",
    "    \"R¬≤\": [r2_with_gp, r2_without_gp]\n",
    "})\n",
    "\n",
    "results.round(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"font-family: Helvetica; line-height: 1.75; color: #000000; text-align: justify\">\n",
    "\n",
    "    \n",
    "We observe that both models have <u>similar</u> performance.\n",
    "<br><br>\n",
    "On <strong>average</strong>, the two models make an error of <strong>¬±13.3 minutes</strong>. For example, if our model predicts that a user will listen to the podcast for <strong>60</strong> minutes, the actual duration could reasonably fall between <strong>46.7 and 73.3 minutes</strong>.\n",
    "<br>\n",
    "From the scatter plots, we can see that both models <strong>are biased toward</strong> users who listen to a podcast very briefly (less than 15 minutes) and those who listen for a long time (more than 80 minutes).\n",
    "<br>\n",
    "<strong>95%</strong> of the errors fall within the range [-27.4; +27.4] minutes. The probability that the models make an error greater or less than 27.4 minutes is 5%.\n",
    "<br><br>\n",
    "To summarize, <span style=\"background-color: #F6CECE; color: #000000;\"><strong>both models have average to poor performance</strong></span>. The RMSE, MAE, and R¬≤ are moderate, but the models are biased.    \n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='submission'></a>\n",
    "# <div style=\" background-color:#162B48; color:white; padding: 12px; line-height: 1.5;\"><strong>8. | Submission</strong></div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------- Train the models over the entire dataset -------------\n",
    "\n",
    "X = df_train.drop(columns = 'Listening_Time_minutes')\n",
    "y = df_train['Listening_Time_minutes']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------- ConditionalModelRouter: Dynamic Prediction Based on Feature Availability -------------\n",
    "\n",
    "class ConditionalModelRouter(BaseEstimator, RegressorMixin):\n",
    "    def __init__(self, model_with_gp, model_without_gp):\n",
    "        self.model_with_gp = model_with_gp\n",
    "        self.model_without_gp = model_without_gp\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        \n",
    "        mask = ~X[\"Guest_Popularity_percentage\"].isna() # Return true or false for each index\n",
    "        self.model_with_gp.fit(X[mask], y[mask]) # Train only for data with Guest Popularity\n",
    "        self.model_without_gp.fit(X[~mask].drop(columns=[\"Guest_Popularity_percentage\"]), y[~mask]) # Train only for data without Guest Popularity\n",
    "        return self\n",
    "\n",
    "    def predict(self, X):\n",
    "        X = X.copy()\n",
    "        mask = ~X[\"Guest_Popularity_percentage\"].isna() # Return true or false for each index\n",
    "        y_pred = np.empty(len(X))\n",
    "        \n",
    "        y_pred[mask] = self.model_with_gp.predict(X[mask]) # Predict only for data with Guest Popularity\n",
    "        y_pred[~mask] = self.model_without_gp.predict(X[~mask].drop(columns=[\"Guest_Popularity_percentage\"])) # Predict only for data without Guest Popularity\n",
    "        return y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------- Testing the ConditionalModelRouter -------------\n",
    "\n",
    "# Model\n",
    "from sklearn.dummy import DummyRegressor\n",
    "\n",
    "# Data\n",
    "X_router_test =  pd.DataFrame({\n",
    "    \"Feature1\": [1, 2, 3, 4],\n",
    "    \"Guest_Popularity_percentage\": [0.8, np.nan, 0.5, np.nan]\n",
    "})\n",
    "\n",
    "y_router_test = np.array([10, 20, 100, 30])\n",
    "\n",
    "# Model\n",
    "model_with = DummyRegressor(strategy=\"mean\")\n",
    "model_without = DummyRegressor(strategy=\"constant\", constant=42)\n",
    "\n",
    "# Router\n",
    "router_test = ConditionalModelRouter(model_with_gp=model_with, model_without_gp=model_without)\n",
    "router_test.fit(X_router_test, y_router_test)\n",
    "\n",
    "# Preds\n",
    "preds = router_test.predict(X_router_test)\n",
    "print(\"Pr√©dictions :\", preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------- Pipeline with the final model n¬∞01 (with Guest Popularity) ----------\n",
    "\n",
    "# Best hyperparameters\n",
    "final_param_xgb_with_gp = {\n",
    "    'n_estimators': 425,\n",
    "    'max_depth': 4,\n",
    "    'learning_rate': 0.01359661519238633,\n",
    "    'subsample': 0.4008805073963276,\n",
    "    'colsample_bytree': 0.8325187832312463,\n",
    "}\n",
    "\n",
    "# Final pipeline\n",
    "pipeline_with_gp = make_pipeline(\n",
    "    preprocessing_pipeline,\n",
    "    XGBRegressor(random_state = 450, **final_param_xgb_with_gp)\n",
    ")\n",
    "\n",
    "\n",
    "# ---------- Pipeline with the final model n¬∞02 (without Guest Popularity) ----------\n",
    "\n",
    "# Best hyperparameters\n",
    "final_param_xgb_without_gp = {\n",
    "    'n_estimators': 339,\n",
    "    'max_depth': 4,\n",
    "    'learning_rate': 0.01530999750231462,\n",
    "    'subsample': 0.40013910962061794,\n",
    "    'colsample_bytree': 0.9824077721256953,\n",
    "}\n",
    "\n",
    "# Final pipeline\n",
    "pipeline_without_gp = make_pipeline(\n",
    "    preprocessing_pipeline,\n",
    "    XGBRegressor(random_state = 450, **final_param_xgb_without_gp)\n",
    ")\n",
    "\n",
    "\n",
    "# ---------- Adding both models to a router ----------\n",
    "\n",
    "router = ConditionalModelRouter(\n",
    "    model_with_gp=pipeline_with_gp,\n",
    "    model_without_gp=pipeline_without_gp\n",
    ")\n",
    "\n",
    "\n",
    "# ---------- Train the models over the entire dataset ----------\n",
    "\n",
    "router.fit(X, y)\n",
    "\n",
    "\n",
    "# ---------- Prediction ----------\n",
    "\n",
    "y_deployment = router.predict(df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Submission\n",
    "submission = pd.DataFrame({'id': df_test.index , 'Listening_Time_minutes': y_deployment.round(3)})\n",
    "submission.to_csv(\"podcast_submission.csv\", index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='conclusion'></a>\n",
    "# <div style=\" background-color:#162B48; color:white; padding: 12px; line-height: 1.5;\"><strong>9. | Conclusion</strong></div>\n",
    "\n",
    "\n",
    "<div style=\"font-family: Helvetica; line-height: 1.75; color: #000000; text-align: justify\">\n",
    "\n",
    "    \n",
    "We have completed our project aimed at predicting how long a user will listen to a podcast.\n",
    "<br><br>\n",
    "<strong><u>In this project, we learned to:</u></strong>\n",
    "\n",
    "<li>Handle missing values efficiently</li>\n",
    "\n",
    "<li>Better understand pipelines</li>\n",
    "\n",
    "<li>Build two models and use a routing pipeline</li>\n",
    "\n",
    "<li>Use Optuna</li>\n",
    "<br><br>\n",
    "<strong><u>Areas for improvement include:</u></strong>\n",
    "\n",
    "<li>Feature engineering</li>\n",
    "\n",
    "<li>Pipelines</li>\n",
    "\n",
    "<li>Evaluation after cross-validation</li>\n",
    "\n",
    "<li>The routing pipeline</li>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='references'></a>\n",
    "# <div style=\" background-color:#162B48; color:white; padding: 12px; line-height: 1.5;\"><strong>10. | References</strong>\n",
    "    \n",
    "<div style=\"font-family: Helvetica; line-height: 2; color: #000000; text-align: justify\">\n",
    "\n",
    "<ul><u><strong>Kaggle Notebook</strong> üìö</u>\n",
    "        <li><a style=\"color: #462F53\" href=\"https://www.kaggle.com/code/vasusoni/predict-podcast-ensemble\">RAPIDS SVC w/ Feature Engineering - [LB 0.856] by Vasu Soni</a></li>\n",
    "    </ul>\n",
    "</div> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "databundleVersionId": 11351736,
     "sourceId": 91715,
     "sourceType": "competition"
    }
   ],
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
